import tensorflow as tf
import os
import time
#===========讀入相關套件============
import sys
sys.path.append('C:/Users/user/models/research/slim/preprocessing')
sys.path.append('C:/Users/user/models/research/slim/nets')
sys.path.append('C:/Users/user/models/research/slim')
from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step
from tensorflow.python.platform import tf_logging as logging
import inception_preprocessing
from inception_v3 import inception_v3, inception_v3_arg_scope

slim = tf.contrib.slim

#===========資料資訊============

###TFRecord資料位置
dataset_dir = 'C:/Users/user/Desktop/flowers'

###訓練模型放的位置
log_dir = 'C:/Users/user/Desktop/log1'

###Pre-trained讀入ckpt檔位置
checkpoint_file = 'C:/Users/user/tmp/checkpoints/inception_v3.ckpt'

###要Resize的影像大小
image_size = 299

###要判的類別有幾類
num_classes = 5

###讀取寫好的label.txt
labels_file = 'C:/Users/user/Desktop/flowers/labels.txt'
labels = open(labels_file, 'r')

###創造labels_to_name
labels_to_name = {}
for line in labels:
    label, string_name = line.split(':')
    string_name = string_name[:-1] #Remove newline
    labels_to_name[int(label)] = string_name

###創造TFRecord的file_pattern
file_pattern = 'flowers_%s_*.tfrecord'

###創造字典了解dataset
items_to_descriptions = {
    'image': 'A 3-channel RGB coloured flower image that is either tulips, sunflowers, roses, dandelion, or daisy.',
    'label': 'A label that is as such -- 0:daisy, 1:dandelion, 2:roses, 3:sunflowers, 4:tulips'
}


#================= 訓練資訊 ==================
###設定Epoch數量
num_epochs = 10

###設定Batch size大小
batch_size = 32

###Learning rate資訊
initial_learning_rate = 0.0002
learning_rate_decay_factor = 0.7
num_epochs_before_decay = 2

#============== 讀入TFRecord資料======================
def get_split(split_name, dataset_dir, file_pattern=file_pattern, file_pattern_for_counting='flowers'):
  
    #First check whether the split_name is train or validation
    if split_name not in ['train', 'validation']:
        raise ValueError('The split_name %s is not recognized. Please input either train or validation as the split_name' % (split_name))

    #Create the full path for a general file_pattern to locate the tfrecord_files
    file_pattern_path = os.path.join(dataset_dir, file_pattern % (split_name))

    #Count the total number of examples in all of these shard
    num_samples = 0
    file_pattern_for_counting = file_pattern_for_counting + '_' + split_name
    tfrecords_to_count = [os.path.join(dataset_dir, file) for file in os.listdir(dataset_dir) if file.startswith(file_pattern_for_counting)]
    for tfrecord_file in tfrecords_to_count:
        for record in tf.python_io.tf_record_iterator(tfrecord_file):
            num_samples += 1

    #Create a reader, which must be a TFRecord reader in this case
    reader = tf.TFRecordReader

    #Create the keys_to_features dictionary for the decoder
    keys_to_features = {
      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),
      'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),
      'image/class/label': tf.FixedLenFeature(
          [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),
    }

    #Create the items_to_handlers dictionary for the decoder.
    items_to_handlers = {
    'image': slim.tfexample_decoder.Image(),
    'label': slim.tfexample_decoder.Tensor('image/class/label'),
    }

    #Start to create the decoder
    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)

    #Create the labels_to_name file
    labels_to_name_dict = labels_to_name

    #Actually create the dataset
    dataset = slim.dataset.Dataset(
        data_sources = file_pattern_path,
        decoder = decoder,
        reader = reader,
        num_readers = 4,
        num_samples = num_samples,
        num_classes = num_classes,
        labels_to_name = labels_to_name_dict,
        items_to_descriptions = items_to_descriptions)

    return dataset


def load_batch(dataset, batch_size, height=image_size, width=image_size, is_training=True):
   
    #First create the data_provider object
    data_provider = slim.dataset_data_provider.DatasetDataProvider(
        dataset,
        common_queue_capacity = 24 + 3 * batch_size,
        common_queue_min = 24)

    #Obtain the raw image using the get method
    raw_image, label = data_provider.get(['image', 'label'])

    #Perform the correct preprocessing for this image depending if it is training or evaluating
    image = inception_preprocessing.preprocess_image(raw_image, height, width, is_training)

    #As for the raw images, we just do a simple reshape to batch it up
    raw_image = tf.expand_dims(raw_image, 0)
    raw_image = tf.image.resize_nearest_neighbor(raw_image, [height, width])
    raw_image = tf.squeeze(raw_image)

    #Batch up the image by enqueing the tensors internally in a FIFO queue and dequeueing many elements with tf.train.batch.
    images, raw_images, labels = tf.train.batch(
        [image, raw_image, label],
        batch_size = batch_size,
        num_threads = 4,
        capacity = 4 * batch_size,
        allow_smaller_final_batch = True)

    return images, raw_images, labels

def run():
    #Create the log directory here. Must be done here otherwise import will activate this unneededly.
    if not os.path.exists(log_dir):
        os.mkdir(log_dir)

    #======================= 訓練模型 =========================
    #Now we start to construct the graph and build our model
    with tf.Graph().as_default() as graph:
        tf.logging.set_verbosity(tf.logging.INFO) #Set the verbosity to INFO level

        #First create the dataset and load one batch
        dataset = get_split('train', dataset_dir, file_pattern=file_pattern)
        images, _, labels = load_batch(dataset, batch_size=batch_size)
        
        ##############################################################
        ##############################################################
        #xs = tf.placeholder(tf.float32, [None, 299, 299, 3])
        #ys = tf.placeholder(tf.int64, [None])

        #Know the number steps to take before decaying the learning rate and batches per epoch
        num_batches_per_epoch = int(dataset.num_samples / batch_size)
        num_steps_per_epoch = num_batches_per_epoch #Because one step is one batch processed
        decay_steps = int(num_epochs_before_decay * num_steps_per_epoch)

        #Create the model inference
        with slim.arg_scope(inception_v3_arg_scope()):
            logits, end_points = inception_v3(images, num_classes = dataset.num_classes, is_training = True)

        exclude = ['InceptionV3/Logits', 'InceptionV3/AuxLogits']
        variables_to_restore = slim.get_variables_to_restore(exclude = exclude)

        one_hot_labels = slim.one_hot_encoding(labels, dataset.num_classes)

        global_step = get_or_create_global_step()
        
        probabilities = tf.nn.softmax(logits)
        predictions = tf.argmax(probabilities, 1)
        
        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( labels=one_hot_labels, logits=logits ))
        train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
        
        correct_prediction = tf.equal(predictions, labels)
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        
        #Now we create a saver function that actually restores the variables from a checkpoint file in a sess
        saver = tf.train.Saver(variables_to_restore)
        def restore_fn(sess):
            return saver.restore(sess, checkpoint_file)

        #Define your supervisor for running a managed session. Do not run the summary_op automatically or else it will consume too much memory
        sv = tf.train.Supervisor(logdir = log_dir, summary_op = None, init_fn = restore_fn)

        #Run the managed session
        with sv.managed_session() as sess:
            
            for e in range(num_epochs):
                aa=0
                for i in range(num_steps_per_epoch):
                    a=sess.run(images)
                    b=sess.run(labels)
                    #print(a.shape)
                    #print(b)
                    sess.run(train_step)
                    acc=sess.run(accuracy)
                    print(acc)
                    aa+=acc/num_steps_per_epoch
                print(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
                print("EPOCH %s 平均Value:%s" %(e,aa))
                print(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>")
                
if __name__ == '__main__':
    run()
